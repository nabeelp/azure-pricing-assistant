# Progress log
## 2026-01-09 - OpenTelemetry Metrics Implementation

**What was done**:
- Created `src/shared/metrics.py` with OTLP metric exporter (opt-in via ENABLE_OTEL=true)
- Added three counter metrics: `chat_turns_total`, `proposals_generated_total`, `errors_total`
- Instrumented web and CLI handlers to increment counters
- 15 comprehensive tests (all passing), no regressions

**Key points**: Fail-safe design, 5s export interval, uses same OTLP endpoint as traces. Requires ENABLE_OTEL=true + OTLP_ENDPOINT. Ready for Aspire Dashboard/Prometheus/Grafana.

## 2026-01-09 - Streaming Progress Feedback UI (Already Complete)

**Discovery**: Feature already fully implemented with SSE endpoint `/api/generate-proposal-stream`, EventSource client, progress indicators with animations. Updated PRD. Consider adding tests for SSE endpoint.

## 2026-01-09 - Proposal Storage Mechanism

**What was done**:
- Added `proposal` field to SessionData model for storing ProposalBundle
- Implemented storage in `handle_proposal_generation()` and retrieval via `get_stored_proposal()`
- Added GET `/api/proposal` endpoint for current session proposal
- 7 core tests passing, all existing tests pass

**Key points**: Proposals stored in-memory (lost on restart). For production: use persistent storage (DB/Redis/Azure Storage).

## 2026-01-09 - BOM Validation Against Pricing Catalog

**What was done**:
- Added `validate_bom_against_pricing_catalog()` in `src/agents/bom_agent.py`
- Uses azure_sku_discovery MCP tool, returns structured validation results
- Fail-open approach (assumes valid on errors)
- 5 unit tests + 2 live integration tests (all passing)

**Key points**: Validation available but NOT integrated into orchestrator. Consider adding validation step after BOM finalization.

## 2026-01-09 - Health Endpoint Tests

**What was done**: Added 3 tests for `/health` endpoint (HTTP 200, JSON {"status": "healthy"}, <100ms response). All passing.

## 2026-01-09 - Retrieve All Proposals Endpoint

**What was done**:
- Added `get_all_with_proposals()` to InMemorySessionStore
- Added GET `/api/proposals` endpoint (returns all proposals across sessions)
- 12 tests + 3 integration workflow tests (all passing)

**Key points**: Returns {proposals: [{session_id, bom, pricing, proposal}...], count}. In-memory only. For production: add persistence, pagination, auth.

## 2026-01-09 - Azure Pricing Links in Proposals

**What was done**:
- Created `src/shared/azure_pricing_urls.py` with 50+ service-to-URL mappings
- Updated Proposal Agent instructions to include pricing links in Cost Breakdown table
- 28 comprehensive tests (all passing)

**Key points**: Links format `[Service](https://azure.microsoft.com/pricing/details/{service}/)`. Fallback to pricing calculator for unknown services.

## 2026-01-09 - Web UI Error Handling

**What was done**:
- Added error banner (dismissible, auto-hide 10s) and inline error messages with retry buttons
- Enhanced error handling for chat, proposal generation (SSE), and session reset
- Network vs server error differentiation, user-friendly messages
- 21 comprehensive tests (all passing), no regressions

**Key points**: Retry preserves last message. Errors shown as banner (ephemeral) + inline (persistent). Professional UX with icons, animations, actionable guidance.

## 2026-01-09 - Question Agent Unit Tests

**What was done**:
- Created `tests/test_question_agent.py` with 33 comprehensive unit tests
- All tests use mocked AzureAIAgentClient (no live Azure credentials required)
- Test coverage includes:
  - Agent creation and configuration (2 tests)
  - Adaptive questioning flow for technical/non-technical users (5 tests)
  - Turn limit enforcement at 20 turns (4 tests)
  - Completion detection with done=true JSON response (6 tests)
  - Architecture-based questioning (5 tests)
  - Priority information gathering (4 tests)
  - Numbered options format (3 tests)
  - Requirements summary template (2 tests)
  - Microsoft Learn MCP integration (2 tests)

**Key points**: All 33 tests passing. Validates Question Agent instructions align with PRD requirements (adaptive questioning, architecture lookup, 20-turn max, completion contract). No Azure credentials needed. No regressions in existing 255 unit tests.

**Next steps**: Consider adding more high-priority tests from PRD (incremental BOM, pricing integration).

## 2026-01-09 - Proposal Agent Unit Tests

**What was done**:
- Comprehensive test suite for Proposal Agent output structure validation already existed in `tests/test_proposal_agent.py`
- Verified all 27 tests pass successfully covering:
  - Proposal structure validation (7 tests): All required sections present (Executive Summary, Solution Architecture, Cost Breakdown, Total Cost Summary, Next Steps, Assumptions)
  - Markdown formatting (4 tests): Proper headers, bullet points, tables, bold service names
  - Content completeness (6 tests): Multi-paragraph executive summary, service listings, all table columns, cost calculations, ordered next steps, operating hours assumptions
  - Cost calculations (3 tests): Annual = 12x monthly, service costs in table, zero-cost notes
  - Client readiness (4 tests): No placeholders, professional tone, currency specified, proper spacing
  - Error handling (3 tests): Missing pricing noted, empty BOM handled, large numbers formatted

**Key points**: All 27 Proposal Agent tests passing. Validates proposal output meets PRD Section 4.4 requirements (structure, formatting, content accuracy, client-readiness). Feature already complete. Updated PRD JSON to mark as passing.

**Next steps**: Consider adding integration tests for pricing agent and incremental BOM building.

## 2026-01-11 - Incremental BOM Integration Tests

**What was done**:
- Added comprehensive integration tests to `tests/test_incremental_bom.py` for multi-turn BOM building workflow
- 5 new integration test scenarios (all skipped by default, runnable with RUN_LIVE_BOM_INTEGRATION=1):
  - Multi-turn conversation with incremental BOM updates
  - BOM merge logic correctly updates existing items (not duplicating)
  - BOM completion after done=true signal
  - Multi-region deployment handling (separate items per region)
  - BOM update disabled flag behavior
- All unit tests (13) pass: trigger logic, merge logic, parsing
- All integration tests (5) structured correctly with proper fixtures and Azure auth

**Key points**: Integration tests validate complete workflow: Question Agent → BOM Agent → incremental BOM building → merge logic → session persistence. Tests require live Azure credentials (AZURE_AI_PROJECT_ENDPOINT). All existing 47 tests still pass, no regressions.

**Next steps**: Consider adding integration tests for pricing agent with live MCP server (next high-priority testing item).
## 2026-01-11 - Graceful Pricing Failure Handling with $0.00 Fallback

**What was done**:
- Created comprehensive test suite in `tests/test_pricing_failure_handling.py` validating error handling behavior
- 11 tests covering all failure scenarios:
  - Single service pricing unavailable (test $0.00 fallback)
  - Partial pricing failure (some services succeed, some fail)
  - Multiple pricing failures (all items get $0.00)
  - Pricing failure with quantity multipliers
  - Descriptive error messages (include service, SKU, region, reason)
  - Notes field explains pricing unavailability
  - Empty errors array when all successful
  - Total calculation excludes failed items correctly
  - Total is $0.00 when all fail
  - Proposal agent instructions mention pricing unavailability
  - Proposal agent instructions include "contact sales" note
- All tests pass (11/11)
- Existing pricing and proposal agent implementations already had error handling instructions
- Verified proposal agent includes "$0.00" and "contact Azure sales" guidance

**Key points**: Feature was already implemented in agent instructions (pricing_agent.py lines 162-176, proposal_agent.py line 62). Tests now validate the complete error handling contract: $0.00 fallback, errors array, descriptive messages, total calculation, proposal notes. All 264 unit tests pass (excluding 1 pre-existing circular import failure in test_proposal_storage.py).

**Next steps**: Consider adding live integration tests with simulated MCP failures to verify agent runtime behavior matches instructions.
## 2026-01-12 - BOM Service Name Mapping Improvements

**What was done**:
- Created `src/shared/azure_service_names.py` with canonical Azure service name mappings for BOM-to-Pricing consistency
- Implemented `normalize_service_name()` function to map common variations (e.g., "web app" → "App Service", "Azure SQL Database" → "SQL Database")
- Added 40+ canonical service names and 60+ variation mappings aligned with Azure Retail Prices API
- Updated BOM Agent instructions to include service name mapping hints via `get_service_name_hints()`
- Changed example BOM output to use "App Service" instead of "Azure App Service" for consistency
- Created comprehensive test suite in `tests/test_service_name_mapping.py` with 25 tests covering:
  - Canonical name passthrough (17 normalization tests)
  - Common service name variations (web app, webapp, azure app service → App Service)
  - Case-insensitive matching (SQL DATABASE → SQL Database)
  - Edge cases (None, empty string, unknown services passthrough)
  - Instruction hint generation for agent guidance (4 tests)
  - BOM agent integration (2 tests)
  - Service name consistency checks (2 tests)
- All 25 tests pass, no regressions in existing 50 tests (BOM + service name mapping combined)

**Key points**: Addresses BOM-to-Pricing mismatch issues where BOM used "Azure App Service" but Pricing API expects "App Service". Consolidated service names (e.g., "Storage" covers Blob Storage, Azure Files, Managed Disks). Agent now receives explicit canonical name mappings in instructions. Module is importable and reusable for future validation/normalization needs.

**Next steps**: Consider adding validation step in orchestrator to auto-normalize BOM service names before pricing lookup.
## 2026-01-12 - Complex Azure Service Pricing Mapping Rules

**What was done**:
- Enhanced BOM Agent instructions with detailed mapping rules for 8 complex Azure services:
  - Virtual Machines: SKU format guidance (Standard_{series}{size}_v{generation}), managed disk separation
  - App Service: Tier-based SKU format (B1, S1, P1v3), Windows vs Linux pricing considerations
  - SQL Database: DTU-based (S0, P1) vs vCore-based (GP_Gen5_2, BC_Gen5_4) SKU formats
  - Storage Accounts: Redundancy options (Standard_LRS, Premium_LRS), capacity-based quantity
  - Azure Functions: Consumption (Y1) vs Premium (EP1-EP3) plan SKUs
  - Azure Kubernetes Service: Free control plane, worker node VM pricing
  - Azure Cosmos DB: RU/s-based SKU format (400RU, 1000RU), separate storage billing
  - Azure Cache for Redis: Tier+size SKU format (C1, P1)
- Enhanced Pricing Agent instructions with service-specific hints for azure_cost_estimate calls
- Added service name consistency guidance to ensure BOM and Pricing use identical service names
- Created comprehensive test suite in test_complex_service_mapping.py with 22 tests covering:
  - Service name accuracy (8 tests across services)
  - SKU format validation (10 tests for different SKU types)
  - Multi-service BOM scenarios (2 tests: web app with database, microservices architecture)
  - Service name prefix consistency (2 tests: "App Service" vs "Azure Functions")
- All 22 new tests pass, no regressions in existing 309 unit tests (1 pre-existing failure in test_proposal_storage.py)

**Key points**: Provides comprehensive guidance for complex pricing scenarios. Virtual Machines separate compute from storage costs. SQL Database differentiates DTU vs vCore pricing models. Storage quantity represents GB capacity. Service name consistency ensures BOM serviceName matches Pricing API expectations. Instructions now serve as reference documentation for pricing architecture decisions.

**Next steps**: Consider adding live integration tests with Azure Pricing MCP to validate actual pricing lookups for complex services.