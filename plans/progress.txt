# Progress log
## 2026-01-09 - OpenTelemetry Metrics Implementation

**What was done**:
- Created `src/shared/metrics.py` with OTLP metric exporter (opt-in via ENABLE_OTEL=true)
- Added three counter metrics: `chat_turns_total`, `proposals_generated_total`, `errors_total`
- Instrumented web and CLI handlers to increment counters
- 15 comprehensive tests (all passing), no regressions

**Key points**: Fail-safe design, 5s export interval, uses same OTLP endpoint as traces. Requires ENABLE_OTEL=true + OTLP_ENDPOINT. Ready for Aspire Dashboard/Prometheus/Grafana.

## 2026-01-09 - Streaming Progress Feedback UI (Already Complete)

**Discovery**: Feature already fully implemented with SSE endpoint `/api/generate-proposal-stream`, EventSource client, progress indicators with animations. Updated PRD. Consider adding tests for SSE endpoint.

## 2026-01-09 - Proposal Storage Mechanism

**What was done**:
- Added `proposal` field to SessionData model for storing ProposalBundle
- Implemented storage in `handle_proposal_generation()` and retrieval via `get_stored_proposal()`
- Added GET `/api/proposal` endpoint for current session proposal
- 7 core tests passing, all existing tests pass

**Key points**: Proposals stored in-memory (lost on restart). For production: use persistent storage (DB/Redis/Azure Storage).

## 2026-01-09 - BOM Validation Against Pricing Catalog

**What was done**:
- Added `validate_bom_against_pricing_catalog()` in `src/agents/bom_agent.py`
- Uses azure_sku_discovery MCP tool, returns structured validation results
- Fail-open approach (assumes valid on errors)
- 5 unit tests + 2 live integration tests (all passing)

**Key points**: Validation available but NOT integrated into orchestrator. Consider adding validation step after BOM finalization.

## 2026-01-09 - Health Endpoint Tests

**What was done**: Added 3 tests for `/health` endpoint (HTTP 200, JSON {"status": "healthy"}, <100ms response). All passing.

## 2026-01-09 - Retrieve All Proposals Endpoint

**What was done**:
- Added `get_all_with_proposals()` to InMemorySessionStore
- Added GET `/api/proposals` endpoint (returns all proposals across sessions)
- 12 tests + 3 integration workflow tests (all passing)

**Key points**: Returns {proposals: [{session_id, bom, pricing, proposal}...], count}. In-memory only. For production: add persistence, pagination, auth.

## 2026-01-09 - Azure Pricing Links in Proposals

**What was done**:
- Created `src/shared/azure_pricing_urls.py` with 50+ service-to-URL mappings
- Updated Proposal Agent instructions to include pricing links in Cost Breakdown table
- 28 comprehensive tests (all passing)

**Key points**: Links format `[Service](https://azure.microsoft.com/pricing/details/{service}/)`. Fallback to pricing calculator for unknown services.

## 2026-01-09 - Web UI Error Handling

**What was done**:
- Added error banner (dismissible, auto-hide 10s) and inline error messages with retry buttons
- Enhanced error handling for chat, proposal generation (SSE), and session reset
- Network vs server error differentiation, user-friendly messages
- 21 comprehensive tests (all passing), no regressions

**Key points**: Retry preserves last message. Errors shown as banner (ephemeral) + inline (persistent). Professional UX with icons, animations, actionable guidance.

## 2026-01-09 - Question Agent Unit Tests

**What was done**:
- Created `tests/test_question_agent.py` with 33 comprehensive unit tests
- All tests use mocked AzureAIAgentClient (no live Azure credentials required)
- Test coverage includes:
  - Agent creation and configuration (2 tests)
  - Adaptive questioning flow for technical/non-technical users (5 tests)
  - Turn limit enforcement at 20 turns (4 tests)
  - Completion detection with done=true JSON response (6 tests)
  - Architecture-based questioning (5 tests)
  - Priority information gathering (4 tests)
  - Numbered options format (3 tests)
  - Requirements summary template (2 tests)
  - Microsoft Learn MCP integration (2 tests)

**Key points**: All 33 tests passing. Validates Question Agent instructions align with PRD requirements (adaptive questioning, architecture lookup, 20-turn max, completion contract). No Azure credentials needed. No regressions in existing 255 unit tests.

**Next steps**: Consider adding more high-priority tests from PRD (incremental BOM, pricing integration).

## 2026-01-09 - Proposal Agent Unit Tests

**What was done**:
- Comprehensive test suite for Proposal Agent output structure validation already existed in `tests/test_proposal_agent.py`
- Verified all 27 tests pass successfully covering:
  - Proposal structure validation (7 tests): All required sections present (Executive Summary, Solution Architecture, Cost Breakdown, Total Cost Summary, Next Steps, Assumptions)
  - Markdown formatting (4 tests): Proper headers, bullet points, tables, bold service names
  - Content completeness (6 tests): Multi-paragraph executive summary, service listings, all table columns, cost calculations, ordered next steps, operating hours assumptions
  - Cost calculations (3 tests): Annual = 12x monthly, service costs in table, zero-cost notes
  - Client readiness (4 tests): No placeholders, professional tone, currency specified, proper spacing
  - Error handling (3 tests): Missing pricing noted, empty BOM handled, large numbers formatted

**Key points**: All 27 Proposal Agent tests passing. Validates proposal output meets PRD Section 4.4 requirements (structure, formatting, content accuracy, client-readiness). Feature already complete. Updated PRD JSON to mark as passing.

**Next steps**: Consider adding integration tests for pricing agent and incremental BOM building.

